from bs4 import BeautifulSoup
import os
import re
from tkinter import Tk, filedialog, messagebox
import sys


def extract_single_chapter(html_content, debug=False):
    """
    é’ˆå¯¹æ€§è§£æï¼šé€‚é…å•pæ ‡ç­¾å†…åµŒå¥—æœªé—­åˆ<p>çš„HTMLç»“æ„
    æ ¸å¿ƒé€»è¾‘ï¼š
    1. å®šä½ç¬¬ä¸€ä¸ªæœ‰å†…å®¹çš„id="concent"çš„pæ ‡ç­¾ï¼ˆå”¯ä¸€å­˜å‚¨å°è¯´å†…å®¹çš„æ ‡ç­¾ï¼‰
    2. æå–è¯¥æ ‡ç­¾å†…æ‰€æœ‰æ–‡æœ¬ï¼ˆè‡ªåŠ¨å¤„ç†æœªé—­åˆåµŒå¥—æ ‡ç­¾ï¼‰
    3. æŒ‰åŸæ®µè½ç»“æ„æ‹†åˆ†ï¼ˆåŸºäºåµŒå¥—<p>çš„ä½ç½®ï¼‰
    4. æ¸…ç†æ ¼å¼æ®‹ç•™ï¼Œä¿ç•™çº¯æ–‡æœ¬
    """
    soup = BeautifulSoup(html_content, 'html.parser')
    novel_text = []

    if debug:
        print("=== è°ƒè¯•æ¨¡å¼ï¼šå¼€å§‹è§£æ ===")

    # æ­¥éª¤1ï¼šæ‰¾åˆ°æ‰€æœ‰id="concent"çš„pæ ‡ç­¾ï¼Œç­›é€‰å‡ºæœ‰å®é™…å†…å®¹çš„é‚£ä¸ª
    concent_tags = soup.find_all('p', id='concent')
    target_tag = None
    for tag in concent_tags:
        # è¿‡æ»¤æ‰ç©ºæ ‡ç­¾ï¼ˆåªä¿ç•™æœ‰æ–‡æœ¬å†…å®¹çš„ï¼‰
        tag_text = tag.get_text(strip=True)
        if tag_text and len(tag_text) > 10:  # è¿‡æ»¤æ‰é•¿åº¦å°äº10çš„ç©ºæ ‡ç­¾
            target_tag = tag
            break

    if not target_tag:
        if debug:
            print("âŒ æœªæ‰¾åˆ°åŒ…å«å†…å®¹çš„id='concent'æ ‡ç­¾")
        return None

    if debug:
        print(f"âœ… æ‰¾åˆ°ç›®æ ‡æ ‡ç­¾ï¼šid='concent'ï¼Œæ–‡æœ¬é•¿åº¦ï¼š{len(target_tag.get_text())}")

    # æ­¥éª¤2ï¼šæå–æ ‡ç­¾å†…æ‰€æœ‰æ–‡æœ¬ï¼ˆBeautifulSoupä¼šè‡ªåŠ¨å¤„ç†æœªé—­åˆæ ‡ç­¾ï¼‰
    full_text = target_tag.get_text()

    # æ­¥éª¤3ï¼šæŒ‰åŸæ®µè½ç»“æ„æ‹†åˆ†ï¼ˆåŸºäºåµŒå¥—<p>çš„è¯­ä¹‰ï¼ŒæŒ‰å¥å­/å¯¹è¯è‡ªç„¶æ‹†åˆ†ï¼‰
    # æ‹†åˆ†è§„åˆ™ï¼šä»¥ä¸­æ–‡æ ‡ç‚¹ï¼ˆã€‚ï¼ï¼Ÿâ€ï¼‰ç»“å°¾çš„ä¸ºä¸€ä¸ªæ®µè½ï¼Œæˆ–å•ç‹¬çš„å¯¹è¯ä¸ºä¸€ä¸ªæ®µè½
    # å¢å¼ºç‰ˆæ‹†åˆ†æ­£åˆ™ï¼šåŒ¹é…ä¸­æ–‡æ ‡ç‚¹+æ¢è¡Œ/ç©ºæ ¼ï¼Œä½œä¸ºæ®µè½åˆ†éš”
    paragraphs = re.split(r'([ã€‚ï¼ï¼Ÿâ€])\s*', full_text)

    # é‡ç»„æ®µè½ï¼ˆå°†æ‹†åˆ†çš„æ ‡ç‚¹å’Œæ–‡æœ¬åˆå¹¶ï¼‰
    current_paragraph = ""
    for part in paragraphs:
        if part in ['ã€‚', 'ï¼', 'ï¼Ÿ', 'â€']:
            if current_paragraph:
                current_paragraph += part
                novel_text.append(current_paragraph.strip())
                current_paragraph = ""
        else:
            current_paragraph += part

    # å¤„ç†æœ€åä¸€ä¸ªæœªå®Œæˆçš„æ®µè½
    if current_paragraph.strip():
        novel_text.append(current_paragraph.strip())

    # æ­¥éª¤4ï¼šè¿‡æ»¤æ— æ•ˆå†…å®¹ï¼Œæ¸…ç†æ ¼å¼
    valid_paragraphs = []
    ignore_keywords = ['å®¢æœQQ', 'åˆ·æ–°æ— æ•ˆ', 'è”ç³»æˆ‘ä»¬', 'ä¸‹ä¸€ç« ', 'ä¸Šä¸€ç« ', 'ç›®å½•']
    for para in novel_text:
        # è¿‡æ»¤ç©ºæ®µè½å’Œè¿‡çŸ­çš„æ— æ„ä¹‰æ®µè½
        if not para or len(para) < 2:
            continue
        # è¿‡æ»¤æ— å…³æ§åˆ¶æ–‡æœ¬
        if any(keyword in para for keyword in ignore_keywords):
            if debug:
                print(f"è¿‡æ»¤æ— å…³æ–‡æœ¬ï¼š{para[:20]}...")
            continue
        valid_paragraphs.append(para)

    if debug:
        print(f"âœ… æ‹†åˆ†åæœ‰æ•ˆæ®µè½æ•°ï¼š{len(valid_paragraphs)}")
        if valid_paragraphs:
            print(f"ç¬¬ä¸€æ®µï¼š{valid_paragraphs[0]}")
            print(f"æœ€åä¸€æ®µï¼š{valid_paragraphs[-1]}")

    # æ‹¼æ¥æˆå®Œæ•´ç« èŠ‚å†…å®¹
    if valid_paragraphs:
        chapter_content = '\n'.join(valid_paragraphs)
        # æ¸…ç†å¤šä½™ç©ºè¡Œ
        chapter_content = re.sub(r'\n+', '\n', chapter_content)
        return chapter_content.strip()

    return None


def get_file_encoding(file_path):
    """è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç ï¼ˆæ”¯æŒå¸¸è§ç¼–ç ï¼‰"""
    encodings = ['utf-8', 'gbk', 'gb2312', 'gb18030', 'latin-1']
    for encoding in encodings:
        try:
            with open(file_path, 'r', encoding=encoding) as f:
                f.read(1024)  # åªè¯»å‰1024å­—èŠ‚æ£€æµ‹ç¼–ç 
            return encoding
        except Exception:
            continue
    return None


def extract_chapter_number(filename):
    """å¢å¼ºç‰ˆç« èŠ‚å·æå–ï¼ˆé€‚é…æ›´å¤šå‘½åæ ¼å¼ï¼‰"""
    pattern = r'(ç¬¬\s*(\d+)\s*ç« )|(chapter\s*(\d+))|(chap\s*(\d+))|(\d+)\s*ç« |(\d+)'
    matches = re.findall(pattern, filename, re.IGNORECASE)
    for match in matches:
        for group in match:
            if group and group.isdigit():
                return int(group)
    return 9999


def get_sorted_html_files(folder_path, recursive=False):
    """è·å–æ’åºåçš„HTMLæ–‡ä»¶åˆ—è¡¨"""
    html_files = []
    for root, dirs, files in os.walk(folder_path):
        for filename in files:
            if filename.lower().endswith(('.html', '.htm')):
                file_path = os.path.join(root, filename)
                chapter_num = extract_chapter_number(filename)
                html_files.append((chapter_num, file_path, filename))
        if not recursive:
            break

    html_files.sort(key=lambda x: x[0])
    return [file_info[1] for file_info in html_files]


def merge_novel_chapters(folder_path, output_filename="å®Œæ•´å°è¯´_é€è§†ç‹‚å…µ.txt", recursive=False, debug=False):
    """åˆå¹¶æ‰€æœ‰ç« èŠ‚"""
    sorted_files = get_sorted_html_files(folder_path, recursive)
    if not sorted_files:
        print("âŒ æœªæ‰¾åˆ°ä»»ä½•HTML/HTMæ–‡ä»¶ï¼")
        return

    print(f"æ‰¾åˆ° {len(sorted_files)} ä¸ªç« èŠ‚æ–‡ä»¶ï¼Œå¼€å§‹æå–...")
    print("-" * 60)

    full_novel = []
    failed_files = []

    for idx, file_path in enumerate(sorted_files, 1):
        try:
            # è‡ªåŠ¨æ£€æµ‹ç¼–ç 
            encoding = get_file_encoding(file_path)
            if not encoding:
                print(f"âŒ è·³è¿‡ {os.path.basename(file_path)}ï¼šæ— æ³•è¯†åˆ«ç¼–ç ")
                failed_files.append(os.path.basename(file_path))
                continue

            # è¯»å–æ–‡ä»¶
            with open(file_path, 'r', encoding=encoding) as f:
                html_content = f.read()

            # æå–ç« èŠ‚å†…å®¹ï¼ˆä»…å¯¹ç¬¬ä¸€ä¸ªæ–‡ä»¶å¼€å¯debugï¼Œé¿å…è¾“å‡ºè¿‡å¤šï¼‰
            chapter_content = extract_single_chapter(html_content, debug=debug and idx == 1)

            if not chapter_content:
                print(f"âš ï¸  è·³è¿‡ {os.path.basename(file_path)}ï¼šæœªæå–åˆ°æœ‰æ•ˆå†…å®¹")
                failed_files.append(os.path.basename(file_path))
                continue

            # æå–ç« èŠ‚æ ‡é¢˜ï¼ˆä¼˜å…ˆå–å‰20å­—ç¬¦å†…åŒ…å«"ç¬¬Xç« "çš„å†…å®¹ï¼‰
            chapter_title = f"ç¬¬{idx}ç« "
            title_match = re.search(r'ç¬¬\s*\d+\s*ç« .*?(?=\n|$)', chapter_content)
            if title_match:
                chapter_title = title_match.group().strip()
            else:
                # è‹¥æœªæ‰¾åˆ°æ˜ç¡®æ ‡é¢˜ï¼Œå–ç¬¬ä¸€æ®µä½œä¸ºæ ‡é¢˜
                first_para = chapter_content.split('\n')[0][:20] + "..." if len(
                    chapter_content.split('\n')[0]) > 20 else chapter_content.split('\n')[0]
                chapter_title = f"ç¬¬{idx}ç«  {first_para}"

            # æ ¼å¼åŒ–ç« èŠ‚
            formatted_chapter = f"ã€{chapter_title}ã€‘\n{chapter_content}\n" + "=" * 80 + "\n"
            full_novel.append(formatted_chapter)

            print(f"âœ… å·²å¤„ç†ï¼š{os.path.basename(file_path)} -> {chapter_title}")

        except Exception as e:
            error_msg = str(e)[:50] + "..." if len(str(e)) > 50 else str(e)
            print(f"âŒ å¤±è´¥ï¼š{os.path.basename(file_path)} - {error_msg}")
            failed_files.append(os.path.basename(file_path))

    # è¾“å‡ºç»“æœ
    print("-" * 60)
    if full_novel:
        output_path = os.path.join(folder_path, output_filename)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(full_novel))

        print(f"ğŸ‰ æ±‡æ€»å®Œæˆï¼")
        print(f"ğŸ“ ä¿å­˜è·¯å¾„ï¼š{output_path}")
        print(f"ğŸ“š æˆåŠŸå¤„ç†ç« èŠ‚æ•°ï¼š{len(full_novel)}")
        print(f"ğŸ“ æ€»å­—ç¬¦æ•°ï¼š{sum(len(chapter) for chapter in full_novel)}")
    else:
        print("âŒ æœªæå–åˆ°ä»»ä½•æœ‰æ•ˆå°è¯´å†…å®¹ï¼")

    # è¾“å‡ºå¤±è´¥æ–‡ä»¶
    if failed_files:
        print(f"\nâš ï¸  å¤„ç†å¤±è´¥/è·³è¿‡çš„æ–‡ä»¶ï¼ˆå…±{len(failed_files)}ä¸ªï¼‰ï¼š")
        for file in failed_files[:5]:
            print(f"  - {file}")
        if len(failed_files) > 5:
            print(f"  - è¿˜æœ‰ {len(failed_files) - 5} ä¸ªæ–‡ä»¶æœªåˆ—å‡º")


def main():
    print("=" * 80)
    print("          å°è¯´æ±‡æ€»å·¥å…·ï¼ˆä¸“å±é€‚é…éœœæœˆçŸ­æ–‡HTMLç»“æ„ï¼‰")
    print("=" * 80)
    print("é€‚é…ç‰¹å¾ï¼šæ‰€æœ‰å†…å®¹åœ¨å•ä¸ªid='concent'çš„pæ ‡ç­¾å†…ï¼ŒåµŒå¥—æœªé—­åˆ<p>æ ‡ç­¾")
    print("åŠŸèƒ½ï¼šè‡ªåŠ¨è¯†åˆ«ç¼–ç ã€æå–æ–‡æœ¬ã€æŒ‰ç« èŠ‚æ’åºã€æ±‡æ€»ä¸ºTXT")
    print("=" * 80)

    # é€‰æ‹©æ–‡ä»¶å¤¹
    root = Tk()
    root.withdraw()
    folder_path = filedialog.askdirectory(title="é€‰æ‹©å°è¯´ç« èŠ‚æ–‡ä»¶å¤¹")
    if not folder_path:
        print("æœªé€‰æ‹©æ–‡ä»¶å¤¹ï¼Œç¨‹åºé€€å‡º")
        return

    # è¯¢é—®é€’å½’å’Œè°ƒè¯•
    recursive = messagebox.askyesno("é€’å½’éå†", "æ˜¯å¦é€’å½’éå†å­æ–‡ä»¶å¤¹ï¼Ÿ")
    debug = messagebox.askyesno("è°ƒè¯•æ¨¡å¼", "æ˜¯å¦å¼€å¯è°ƒè¯•æ¨¡å¼ï¼Ÿï¼ˆé¦–æ¬¡ä½¿ç”¨å»ºè®®å¼€å¯ï¼‰")

    # å¼€å§‹æ±‡æ€»
    merge_novel_chapters(folder_path, recursive=recursive, debug=debug)

    input("\næŒ‰å›è½¦é”®é€€å‡º...")


if __name__ == "__main__":
    main()